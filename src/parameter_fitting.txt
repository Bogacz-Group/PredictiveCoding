PC supervised
    - PC reversed MNIST
        Best val acc: 0.952, Best params - lr_x: 0.001, lr_p: 0.001, weight_decay: 0, optimizer_x_fn: <class 'torch.optim.sgd.SGD'>, optimizer_p_fn: <class 'torch.optim.adam.Adam'>, activation_fn: <class 'torch.nn.modules.activation.ReLU'>
        Best val acc: 0.958, Best params - lr_x: 0.01, lr_p: 0.01, weight_decay: 0, optimizer_x_fn: <class 'torch.optim.sgd.SGD'>, optimizer_p_fn: <class 'torch.optim.adam.Adam'>, activation_fn: <class 'torch.nn.modules.activation.ReLU'>
        Best val acc: 0.964, Best params - lr_x: 0.01, lr_p: 0.01, weight_decay: 0, optimizer_x_fn: <class 'torch.optim.sgd.SGD'>, optimizer_p_fn: <class 'torch.optim.adam.Adam'>, activation_fn: <class 'torch.nn.modules.activation.Tanh'>
        
    - PC normal MNIST
        Best val acc: 0.802, Best params - lr_x:0.001, lr_p:0.001, weight_decay:0, optimizer_x_fn:<class 'torch.optim.adam.Adam'>, optimizer_p_fn:<class 'torch.optim.adam.Adam'>, activation_fn:<class 'torch.nn.modules.activation.ReLU'>
        Best val acc: 0.814, Best params - lr_x:0.001, lr_p:0.001, weight_decay:0, optimizer_x_fn:<class 'torch.optim.adam.Adam'>, optimizer_p_fn:<class 'torch.optim.adam.Adam'>, activation_fn:<class 'torch.nn.modules.activation.Tanh'>
        Best val acc: 0.818, Best params - lr_x:0.001, lr_p:0.001, weight_decay:0, optimizer_x_fn:<class 'torch.optim.adam.Adam'>, optimizer_p_fn:<class 'torch.optim.sgd.SGD'>, activation_fn:<class 'torch.nn.modules.activation.ReLU'>
        Best val acc: 0.842, Best params - lr_x:0.001, lr_p:0.001, weight_decay:0, optimizer_x_fn:<class 'torch.optim.adam.Adam'>, optimizer_p_fn:<class 'torch.optim.sgd.SGD'>, activation_fn:<class 'torch.nn.modules.activation.Tanh'>
        Best val acc: 0.856, Best params - lr_x:0.001, lr_p:0.001, weight_decay:0.001, optimizer_x_fn:<class 'torch.optim.adam.Adam'>, optimizer_p_fn:<class 'torch.optim.sgd.SGD'>, activation_fn:<class 'torch.nn.modules.activation.Tanh'>
        Best val acc: 0.862, Best params - lr_x:0.01, lr_p:0.001, weight_decay:0, optimizer_x_fn:<class 'torch.optim.adam.Adam'>, optimizer_p_fn:<class 'torch.optim.adam.Adam'>, activation_fn:<class 'torch.nn.modules.activation.Tanh'>
        Best val acc: 0.868, Best params - lr_x:0.01, lr_p:0.001, weight_decay:0, optimizer_x_fn:<class 'torch.optim.adam.Adam'>, optimizer_p_fn:<class 'torch.optim.sgd.SGD'>, activation_fn:<class 'torch.nn.modules.activation.Tanh'>
        Best val acc: 0.87, Best params - lr_x:0.01, lr_p:0.001, weight_decay:0.001, optimizer_x_fn:<class 'torch.optim.adam.Adam'>, optimizer_p_fn:<class 'torch.optim.adam.Adam'>, activation_fn:<class 'torch.nn.modules.activation.ReLU'>
        Best val acc: 0.876, Best params - lr_x:0.01, lr_p:0.001, weight_decay:0.001, optimizer_x_fn:<class 'torch.optim.adam.Adam'>, optimizer_p_fn:<class 'torch.optim.sgd.SGD'>, activation_fn:<class 'torch.nn.modules.activation.Tanh'>
        Best val acc: 0.896, Best params - lr_x:0.1, lr_p:0.001, weight_decay:0.001, optimizer_x_fn:<class 'torch.optim.adam.Adam'>, optimizer_p_fn:<class 'torch.optim.adam.Adam'>, activation_fn:<class 'torch.nn.modules.activation.ReLU'>

    - PC V-model/dual model
        Best val acc: 0.158, Best params: "lr_x": 0.001, "lr_p": 0.001, "weight_decay": 0, "activation_fn": <class 'torch.nn.modules.activation.ReLU'>, "optimizer_x_fn": <class 'torch.optim.adam.Adam'>, "optimizer_p_fn": <class 'torch.optim.adam.Adam'>
        Best val acc: 0.17, Best params: "lr_x": 0.001, "lr_p": 0.001, "weight_decay": 0, "activation_fn": <class 'torch.nn.modules.activation.Tanh'>, "optimizer_x_fn": <class 'torch.optim.adam.Adam'>, "optimizer_p_fn": <class 'torch.optim.adam.Adam'>
        Best val acc: 0.172, Best params: "lr_x": 0.001, "lr_p": 0.001, "weight_decay": 0.001, "activation_fn": <class 'torch.nn.modules.activation.ReLU'>, "optimizer_x_fn": <class 'torch.optim.adam.Adam'>, "optimizer_p_fn": <class 'torch.optim.adam.Adam'>
        Best val acc: 0.268, Best params: "lr_x": 0.001, "lr_p": 0.1, "weight_decay": 0.001, "activation_fn": <class 'torch.nn.modules.activation.ReLU'>, "optimizer_x_fn": <class 'torch.optim.sgd.SGD'>, "optimizer_p_fn": <class 'torch.optim.adam.Adam'>
        Best val acc: 0.302, Best params: "lr_x": 0.01, "lr_p": 0.1, "weight_decay": 0, "activation_fn": <class 'torch.nn.modules.activation.Tanh'>, "optimizer_x_fn": <class 'torch.optim.sgd.SGD'>, "optimizer_p_fn": <class 'torch.optim.adam.Adam'>
        Best val acc: 0.344, Best params: "lr_x": 0.1, "lr_p": 0.001, "weight_decay": 0, "activation_fn": <class 'torch.nn.modules.activation.ReLU'>, "optimizer_x_fn": <class 'torch.optim.adam.Adam'>, "optimizer_p_fn": <class 'torch.optim.adam.Adam'>
        Best val acc: 0.972, Best params: "lr_x": 0.1, "lr_p": 0.01, "weight_decay": 0, "activation_fn": <class 'torch.nn.modules.activation.ReLU'>, "optimizer_x_fn": <class 'torch.optim.adam.Adam'>, "optimizer_p_fn": <class 'torch.optim.adam.Adam'>
        Best val acc: 1.0, Best params: "lr_x": 1, "lr_p": 0.01, "weight_decay": 0.001, "activation_fn": <class 'torch.nn.modules.activation.Tanh'>, "optimizer_x_fn": <class 'torch.optim.adam.Adam'>, "optimizer_p_fn": <class 'torch.optim.adam.Adam'>